---
layout: default
title: Behind the Interface
nav_order: 5
---

# Behind the Interface: Layers of Bias Hidden in Machine Learning

> ***Behind the interface** examines the technocultural dimensions of working with (text) data, with the understanding that computing infrastructure and practices are not neutral but emerge from complicated historical lineages that often remain hidden to the user. By peering behind the interface at the circumstances, biases and assumptions surrounding the layers of decision-making involved in developing technologies, we encourage you to consider how structures of inequality become hard-coded into the tools and conventions of data science and how we can work towards opening up new sites of resistance and critique.*

## Dominant Datasets

As we have already  in the lesson, there are numerous in which natural language processing can be . is the training dataset used in machine learning to recognize patterns that will be applied to .

For example, 

## Data Sovereignty

While it is important to ensure that natural language processing systems are designed with principles of equity in mind, there are also respects in which efforts at inclusion can put minoritized communities at further risk. As Ruha Benjamin notes, when.

Benjamin does not , and stresses that there are sites of resistance to the new Jim code.


The importance of working together with communities who are impacted  and their data sovereignty. 

Initiatives like the Corpus of Regional African American Language (CORAAL) project, which  point to possibilit

## Algorithmic Opacity

As Ananny and Crawford highlight, 

<br />
Next --> [Learn More](learn-more.html) 
