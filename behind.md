---
layout: default
title: Behind the Interface
nav_order: 5
---

# Behind the Interface: Layers of Bias Hidden in Machine Learning

> ***Behind the interface** examines the technocultural dimensions of working with (text) data, with the understanding that computing infrastructure and practices are not neutral but emerge from complicated historical lineages that often remain hidden to the user. By peering behind the interface at the circumstances, biases and assumptions surrounding the layers of decision-making involved in developing technologies, we encourage you to consider how structures of inequality become hard-coded into the tools and conventions of data science and how we can work towards opening up new sites of resistance and critique.*

<hr />

**\*\* COMING SOON \*\***

<!--

## Dominant Datasets

[Safiya Noble](https://safiyaunoble.com/), [Joy Buolamwini](https://www.media.mit.edu/people/joyab/overview/), [Cathy Oâ€™Neil](https://mathbabe.org/) and others have drawn attention to the latent biases and assumptions encoded into algorithmically driven processes such as search engine term autocompletions and facial recognition. As we have already encountered in the lesson, natural language processing is no less immune to being shaped by the social-technical  can be . is the training dataset used in machine learning to recognize patterns that will be applied to . For example, choices in how to label data, what data is included 

For example, 

Initiatives like the [Corpus of Regional African American Language (CORAAL)](https://oraal.uoregon.edu/coraal) project, which  point to possibilities

## Data Sovereignty

Conversely, there are complex ethical questions surrounding the use of data from minoritized communities; community protocols; turning texts into data
While it is important to ensure that natural language processing systems are designed with principles of equity in mind, there are also respects in which efforts at inclusion can put minoritized communities at further risk. As Ruha Benjamin notes, when.

Benjamin does not , and stresses that there are sites of resistance to the new Jim code.


The importance of working together with communities who are impacted  and their data sovereignty. 



## Algorithmic Opacity

One of the challenges to engaging in a critique of machine learning processes is the As Ananny and Crawford highlight, 

-->

